---
title: "Regression - Statistical Analysis"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)
library(readxl)
```


```{r echo=FALSE} 
original = tibble(        ## Clean the original weight data
  read.csv("./dataset/Student_Weight_Status_Category_Reporting_Results__Beginning_2010.csv")
) %>%
  janitor::clean_names() %>%
  select(-location_code, -region, -area_name)  # the only location information we need is county name
```


```{r echo=FALSE} 
# Clean data set with geo location information
coordinates = tibble(
  read.csv("./dataset/Geocodes_USA_with_Counties.csv")
) %>%
  filter(state == "NY") %>%  # filter out counties outside NY state
  select(county, latitude, longitude) %>% # only information we need is county name and geo location
  drop_na() %>%
  group_by(county) %>%
  summarise(latitude = mean(latitude), longitude = mean(longitude)) %>% #different location in each county variaed slightly, so we take the mean of each county's geo location
  filter(!county == "") %>% # one county's name input is blank
  mutate(county = toupper(county)) # to switch county name to uppercase
```


```{r echo=FALSE}
# combine two data set
weight_df = left_join(original, coordinates, by = "county")
```


```{r echo=FALSE}
# Further original data cleaning for linear regression analysis
linear_df = weight_df %>%
  filter(!sex == "ALL") %>%
  filter(!grade_level == "DISTRICT TOTAL") %>%
  mutate(
    sex = if_else(sex == "MALE", 0, 1),
    grade_level = if_else(grade_level == "ELEMENTARY", 0, 1)
  ) %>%
  drop_na() %>%
  filter(year_reported %in% c("2018-2019")) #only analyzing data in year 2018-2019
```


```{r echo=FALSE}
# Import tidy and join the median income and food insecurity data
income = read_xlsx("./dataset/median_income.xlsx") %>%
  janitor::clean_names() %>%
  rename(county = region_county) %>%
  mutate(median_income = median_income*0.001,  # convert the income unit from $100,000 to 100k format, large values will reduce model's efficiency
         county = toupper(county))

food_insecurity = read_xlsx("./dataset/food_insecurity.xlsx") %>%
  janitor::clean_names() %>%
    rename(county = region_county) %>%
  rename(food_insecurity_p = percentage) %>%
  mutate(county = toupper(county))

linear_df2 = left_join(linear_df, income, by = "county")
linear_df3 = left_join(linear_df2, food_insecurity, by = "county")
```

Before doing the linear regression model, I used two types of transformation to improve the adequacy, a. y' = log(y), b. y'= y^0.5, Q_Q plot showed that the log tansformation has improved data's normality.  
```{r echo=FALSE}
# Normality check
qqnorm(log(linear_df$percent_overweight_or_obese))

hist(log(linear_df$percent_overweight_or_obese))
```
Above are the Q-Q plot and histogram of overweight/obesity data after log transformation.  Q-Q plot is perfectly linear distributed, histogram is normally distributed with a little left skewness.  Overall, the normality assumption is satisfied.  

In the beginning we used included 4 independent variables, grade level, median income, food insecurity and gender, however the model summary showed there is a very weak correlation between gender and our dependent variable - percent overweight and obese, so we took gender factor out, model is furthurly improved, left four variables all significantly influenced the percent overweight and obese.

## Statistics Model
## log(y) = 4.54 + 0.16x1 - 0.01x2 - 0.03x3
y = percent overweight or obese  
x1 = grade level  
x2 = median income (kilodollar)  
x3 = food insecurity percentage

```{r}
# regression model
lm_1 = lm(log(percent_overweight_or_obese) ~ grade_level + median_income + food_insecurity_p, data = linear_df3) 
summary(lm_1)

par(mfrow = c(2, 2))
plot(lm_1)
```

