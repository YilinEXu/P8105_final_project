---
title: "Midterm Project"
author: Jiayi Zhou
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(readxl)

knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

## Problem 1: Data

**Description on the raw dataset:**
The dog weights raw dataset has six variables. The first column contains the date of each weighing from August 12nd, 2018 to September 7th, 2020, while some dates in this period were not recorded. The second to fifth columns contain information about the weights of three dogs and a standard object: Raisin, Simon, Gagne, and std. All weights were recorded in the combination of Lbs and Oz. The last column contains occasional notes. My goal is to clean and preserve valuable data of the dataset, then report summarizations and trends.

**First dataframe about dog weights**
```{r}
dogweights_df =
  read_excel("./data/dogweights_07sept2020.xlsx", skip = 1) %>% 
  janitor::clean_names() %>%
  mutate(date = as.numeric(date),
         date = janitor::excel_numeric_to_date(date)) %>% 
  select(-x6) %>% 
  pivot_longer(
    raisin:std,
    names_to = "dognames_and_std",
    values_to = "weights"
  ) %>% 
  separate(weights, into = c("Lbs", "Oz"), sep = " ") %>% 
  mutate(
    Lbs = as.numeric(Lbs),
    Oz = as.numeric(Oz),
    weights_in_lbs = Lbs + Oz * 0.0625
    ) %>% 
  #drop_na(weights_in_lbs, date) %>% 
  select(-Lbs, -Oz)

dogweights_df
```

**Descriptions of the steps for tidying:**
The observations in "date" were shown as serial numbers after importation. Thus, I first transfered "date" to numeric variable, then the excel_numeric_to_date from the janitor package was used to convert the serial numbers to date class. Next, I put all dog names and the "std" into the "dognames_and_std" columns using pivot_longer since they can all be categorized as names. All weights were organized into "weights_in_lbs" columns. To convert the weight unit, separation of the Lbs and Oz in the same cell was done first. Then, (weights(Oz)*0.0625) was added back to weights(Lbs) to get the whole weight in single unit Lbs.

**About NAs:**
I chose to drop NAs in the tidied dataset. After pivoting, dropping the NAs in weight will only delete the observations that have no weight recorded for one specific name (dogs or std) on the specific date. I chose to drop the NAs in “date” too, even though there is weight information associated with the NAs in “date”. This is because weight records without date, as well as dates without weight records, may not be useful for data analysis and plot generation.

**Second dataframe about notes**
```{r}
notes_df =
  read_excel("./data/dogweights_07sept2020.xlsx", skip = 1) %>% 
  janitor::clean_names() %>%
  mutate(date = as.numeric(date),
         date = janitor::excel_numeric_to_date(date)) %>% 
  rename(note = x6) %>% 
  select(date, note) %>% 
  drop_na(date, note)

notes_df
```

**Export the two dataframes as CSVs**
```{r}
write.csv(dogweights_df, "./data/dogweights.csv")
write.csv(notes_df, "./data/notes.csv")
```

## Problem 2: EDA

**Description of the cleaned dogweights_df dataset:**
The tidy dataset is a tibble: `r ncol(dogweights_df)` x `r nrow(dogweights_df)`. The 3 variables are "date", "dognames_and_std", and "weights_in_lbs". 

**Unique dates:**
```{r}
unique_dates=
  dogweights_df %>% 
  distinct(date) %>% 
  nrow()

unique_dates
```
There are `r unique_dates` unique dates in the tidy dog-weights dataset.

**Table showing the dog names with their associate number of observation, average weight, and the standard deviation:**
```{r}
dogweights_df %>% 
  filter(dognames_and_std %in% c("raisin", "simone", "gagne")) %>% 
  group_by(dognames_and_std) %>%
  rename(dognames = dognames_and_std) %>% 
  summarize(
    number_of_obs = n(),
    average_weight = mean(weights_in_lbs),
    sd_of_weight = sd(weights_in_lbs)
  ) %>% 
   knitr::kable()
```


## Problem 3: Visualization
```{r}
library(patchwork)
```

```{r}
distribution_of_weight = 
  dogweights_df %>% 
  filter(dognames_and_std %in% c("raisin", "simone", "gagne")) %>% 
  group_by(dognames_and_std) %>% 
  rename(dognames = dognames_and_std) %>% 
  mutate(
    dognames = factor(dognames, levels = c("gagne", "simone", "raisin"))
    ) %>% 
  ggplot(aes(x = dognames, y = weights_in_lbs)) +
  geom_boxplot(aes(color = dognames)) +
  labs(x = "Dog name",
       y = "Weight (Lbs)",
       title = "Weight distribution for each dog")

weight_over_time = 
  dogweights_df %>% 
  filter(dognames_and_std %in% c("raisin", "simone", "gagne")) %>% 
  group_by(dognames_and_std) %>% 
  rename(dognames = dognames_and_std) %>% 
  mutate(
    dognames = factor(dognames, levels = c("gagne", "simone", "raisin"))
    ) %>% 
  ggplot(aes(x = date, y = weights_in_lbs, color = dognames)) +
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth() +
  labs(x = "Date",
       y = "Weight (Lbs)",
       title = "Weight change for each dog over time")

distribution_of_weight + weight_over_time
```

**Weight Distribution:** The weight distributions of Gagne is relatively left-skewed with more lower bound outliers compare to Simone's normally distributed weight, while they have similar distribution ranges and medians around 10. The distribution of Raisin's weight is close to normal with several extreme outliers. It also has a much larger median, around 18, compare to the other two dogs.

**Weight Change:** Raisin's weight has been on a decreasing trend and started to increase gradually since October 2019. Simone's weight did not vary too much over the three-years period. Gagne's weight started to decrease rapidly since April 2019. He died on September 8th, 2019 according to the note.



